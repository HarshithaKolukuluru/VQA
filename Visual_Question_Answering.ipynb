{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Visual Question Answering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNrWVxiDUCSys8hNXGvPLal",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JKashyap46/ai5-VQA/blob/main/Visual_Question_Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtNQXDo73JEV"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "\n",
        "import operator\n",
        "\n",
        "import pandas as pd\n",
        "import progressbar\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle as pk\n",
        "from collections import defaultdict\n",
        "from itertools import zip_longest\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import spacy\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46cW9SDzqSqe"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrWSHQR-rAUz",
        "outputId": "1fa381f4-2ff9-4c1f-dce9-dbf0cc837adf"
      },
      "source": [
        "project_id = 'ai5-c1-group3'\n",
        "bucket_name = 'vqa-dataset-bucket'\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb1M66Mwr6Jh",
        "outputId": "482862f7-7c09-4ba8-b527-74c87de5a9dd"
      },
      "source": [
        "# !gsutil cp gs://{bucket_name}/v2_Questions_Val_mscoco.zip ./vqa-dataset-bucket/v2_Questions_Val_mscoco.zip\n",
        "# !gsutil cp gs://{bucket_name}/v2_Annotations_Val_mscoco.zip ./vqa-dataset-bucket/v2_Annotations_Val_mscoco.zip\n",
        "!gsutil cp gs://{bucket_name}/val2014.zip ./vqa-dataset-bucket/val2014.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://vqa-dataset-bucket/val2014.zip...\n",
            "/ [1 files][  6.2 GiB/  6.2 GiB]   49.3 MiB/s                                   \n",
            "Operation completed over 1 objects/6.2 GiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5zfNMp9sErE"
      },
      "source": [
        "# with zipfile.ZipFile(os.path.join('/content/vqa-dataset-bucket/','v2_Questions_Val_mscoco.zip')) as zfile:\n",
        "#   zfile.extractall('/content/vqa-dataset-bucket/')\n",
        "\n",
        "# with zipfile.ZipFile(os.path.join('/content/vqa-dataset-bucket/','v2_Annotations_Val_mscoco.zip')) as zfile:\n",
        "#   zfile.extractall('/content/vqa-dataset-bucket/')\n",
        "\n",
        "with zipfile.ZipFile(os.path.join('/content/vqa-dataset-bucket/','val2014.zip')) as zfile:\n",
        "  zfile.extractall('/content/vqa-dataset-bucket/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u81Jk4jwsJm3",
        "outputId": "3f6c6d00-3563-473e-d273-acaf23f2f517"
      },
      "source": [
        "# !gsutil cp  /content/vqa-dataset-bucket/v2_OpenEnded_mscoco_val2014_questions.json gs://{bucket_name}/v2_OpenEnded_mscoco_val2014_questions.json\n",
        "# !gsutil cp  /content/vqa-dataset-bucket/v2_mscoco_val2014_annotations.json gs://{bucket_name}/v2_mscoco_val2014_annotations.json\n",
        "# !gsutil -m cp -r  /content/vqa-dataset-bucket/val2014 gs://{bucket_name}/val2014\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BucketNotFoundException: 404 gs://{bucket_name} bucket does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm5U9tXYsOdR",
        "outputId": "362e2bcd-b6ef-4976-eed6-e8955213f906"
      },
      "source": [
        "!gsutil cp gs://{bucket_name}/v2_OpenEnded_mscoco_val2014_questions.json ./vqa-dataset-bucket/v2_OpenEnded_mscoco_val2014_questions.json\n",
        "!gsutil cp gs://{bucket_name}/v2_mscoco_val2014_annotations.json ./vqa-dataset-bucket/v2_mscoco_val2014_annotations.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://vqa-dataset-bucket/v2_OpenEnded_mscoco_val2014_questions.json...\n",
            "/ [1 files][ 19.3 MiB/ 19.3 MiB]                                                \n",
            "Operation completed over 1 objects/19.3 MiB.                                     \n",
            "Copying gs://vqa-dataset-bucket/v2_mscoco_val2014_annotations.json...\n",
            "| [1 files][163.8 MiB/163.8 MiB]                                                \n",
            "Operation completed over 1 objects/163.8 MiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h71i8u9H3upg"
      },
      "source": [
        "questions = json.load(open('./vqa-dataset-bucket/v2_OpenEnded_mscoco_val2014_questions.json'))\n",
        "annotation = json.load(open('./vqa-dataset-bucket/v2_mscoco_val2014_annotations.json'))\n",
        "annotations = annotation['annotations']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5WYNmPro1P1D",
        "outputId": "c4a6b269-1c97-4290-9148-4597b83feba2"
      },
      "source": [
        "annotations_df = pd.DataFrame(annotations)\n",
        "annotations_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_type</th>\n",
              "      <th>multiple_choice_answer</th>\n",
              "      <th>answers</th>\n",
              "      <th>image_id</th>\n",
              "      <th>answer_type</th>\n",
              "      <th>question_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>none of the above</td>\n",
              "      <td>down</td>\n",
              "      <td>[{'answer': 'down', 'answer_confidence': 'yes'...</td>\n",
              "      <td>262148</td>\n",
              "      <td>other</td>\n",
              "      <td>262148000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what are the</td>\n",
              "      <td>watching</td>\n",
              "      <td>[{'answer': 'spectating', 'answer_confidence':...</td>\n",
              "      <td>262148</td>\n",
              "      <td>other</td>\n",
              "      <td>262148001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is</td>\n",
              "      <td>picnic table</td>\n",
              "      <td>[{'answer': 'table', 'answer_confidence': 'yes...</td>\n",
              "      <td>262148</td>\n",
              "      <td>other</td>\n",
              "      <td>262148002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what</td>\n",
              "      <td>foodiebakercom</td>\n",
              "      <td>[{'answer': 'foodiebakercom', 'answer_confiden...</td>\n",
              "      <td>393225</td>\n",
              "      <td>other</td>\n",
              "      <td>393225000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is this a</td>\n",
              "      <td>no</td>\n",
              "      <td>[{'answer': 'no', 'answer_confidence': 'yes', ...</td>\n",
              "      <td>393225</td>\n",
              "      <td>yes/no</td>\n",
              "      <td>393225001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       question_type multiple_choice_answer  ... answer_type  question_id\n",
              "0  none of the above                   down  ...       other    262148000\n",
              "1       what are the               watching  ...       other    262148001\n",
              "2            what is           picnic table  ...       other    262148002\n",
              "3               what         foodiebakercom  ...       other    393225000\n",
              "4          is this a                     no  ...      yes/no    393225001\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeVYoUZ_25u-",
        "outputId": "d6aff35c-ac40-4a6c-a812-7c26f26a2851"
      },
      "source": [
        "annotations_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(214354, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7CYAsbG4L-5"
      },
      "source": [
        "total_questions = len(questions['questions'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_cyVCNj9x2w",
        "outputId": "e293b49f-2fbd-4bff-c5f8-d5f1c24523ac"
      },
      "source": [
        "training_questions = questions['questions'][0:50000]\n",
        "train_questions = []\n",
        "progress = progressbar.ProgressBar()\n",
        "for index in progress(range(50000)):\n",
        "  train_questions.append(training_questions[index]['question'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (50000 of 50000) |##################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFw81ngd2jn9"
      },
      "source": [
        "questions_df = pd.DataFrame(training_questions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XYy_Zao52mj2",
        "outputId": "53bae244-a959-4f9b-a7ea-78bc7ae353d2"
      },
      "source": [
        "questions_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>question</th>\n",
              "      <th>question_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262148</td>\n",
              "      <td>Where is he looking?</td>\n",
              "      <td>262148000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>262148</td>\n",
              "      <td>What are the people in the background doing?</td>\n",
              "      <td>262148001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>262148</td>\n",
              "      <td>What is he on top of?</td>\n",
              "      <td>262148002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>393225</td>\n",
              "      <td>What website copyrighted the picture?</td>\n",
              "      <td>393225000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>393225</td>\n",
              "      <td>Is this a creamy soup?</td>\n",
              "      <td>393225001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   image_id                                      question  question_id\n",
              "0    262148                          Where is he looking?    262148000\n",
              "1    262148  What are the people in the background doing?    262148001\n",
              "2    262148                         What is he on top of?    262148002\n",
              "3    393225         What website copyrighted the picture?    393225000\n",
              "4    393225                        Is this a creamy soup?    393225001"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtwsi18k7Y_l"
      },
      "source": [
        "def most_freq_answer(values):\n",
        "    ans_dict = {}\n",
        "    for index in range(10):\n",
        "        ans_dict[values[index]['answer']] = 1\n",
        "    for index in range(10):\n",
        "        ans_dict[values[index]['answer']] += 1\n",
        "\n",
        "    return max(ans_dict.items(), key = operator.itemgetter(1))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaeRe7Ch6Mjs",
        "outputId": "41c6422f-1d2b-4f35-e812-603f7646668b"
      },
      "source": [
        "progress = progressbar.ProgressBar()\n",
        "answer_train = []\n",
        "for index in progress(range(50000)):\n",
        "  answer_train.append(most_freq_answer(annotations[index]['answers']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (50000 of 50000) |##################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysiPJBiq7pyP",
        "outputId": "a0d0c12b-b544-49c5-9471-6634f5e0b2bb"
      },
      "source": [
        "len(answer_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_5D0elv-rlq",
        "outputId": "a23193c4-bc47-4604-99d9-7ac2c9644139"
      },
      "source": [
        "images_train = []\n",
        "progress = progressbar.ProgressBar()\n",
        "for index in progress(range(50000)):\n",
        "  images_train.append(training_questions[index]['image_id'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (50000 of 50000) |##################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUGU3BrXBdYU"
      },
      "source": [
        "def freq_answers(training_questions, answer_train, images_train, upper_lim):\n",
        "\n",
        "    freq_ans = defaultdict(int)\n",
        "    for ans in answer_train:\n",
        "        freq_ans[ans] += 1\n",
        "\n",
        "    sort_freq = sorted(freq_ans.items(), key=operator.itemgetter(1), reverse=True)[0:upper_lim]\n",
        "    top_ans, top_freq = zip(*sort_freq)\n",
        "    new_answers_train = list()\n",
        "    new_questions_train = list()\n",
        "    new_images_train = list()\n",
        "    for ans, ques, img in zip(answer_train, training_questions, images_train):\n",
        "        if ans in top_ans:\n",
        "            new_answers_train.append(ans)\n",
        "            new_questions_train.append(ques)\n",
        "            new_images_train.append(img)\n",
        "\n",
        "    return (new_questions_train, new_answers_train, new_images_train, top_ans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yu7rfVE4euJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0KJ4s-4A_MO",
        "outputId": "3f85c51b-2336-4d62-c435-b93316bd6eaf"
      },
      "source": [
        "upper_lim = 1000 #Number of most frequently occurring answers in COCOVQA (85%+)\n",
        "training_questions, answers_train, images_train,top_ans = freq_answers(train_questions, answer_train, images_train, upper_lim)\n",
        "print (len(training_questions), len(answers_train),len(images_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39177 39177 39177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6sch4TXASAA"
      },
      "source": [
        "lbl = LabelEncoder()\n",
        "lbl.fit(answers_train)\n",
        "nb_classes = len(list(lbl.classes_))\n",
        "pk.dump(lbl, open('./label_encoder.sav','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnmUGTQ3Etae",
        "outputId": "e49bc7d3-fe84-4d09-fde6-b0a745c68876"
      },
      "source": [
        "nb_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbzDFokvBprH"
      },
      "source": [
        "def get_questions_sum(questions, nlp):\n",
        "    nb_samples = len(questions)\n",
        "    word2vec_dim = nlp(questions[0])[0].vector.shape[0]\n",
        "    ques_matrix = np.zeros((nb_samples, word2vec_dim))\n",
        "    for index in range(len(questions)):\n",
        "        tokens = nlp(questions[index])\n",
        "        for j in range(len(tokens)):\n",
        "            ques_matrix[index,:] += tokens[j].vector\n",
        "\n",
        "    return ques_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGmM95D_V3ys",
        "outputId": "ad65a197-b779-4d05-d3ef-e5a5e2e29e1f"
      },
      "source": [
        "# !gsutil cp gs://{bucket_name}/GoogleNews-vectors-negative300.bin.gz ./vqa-dataset-bucket/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://vqa-dataset-bucket/GoogleNews-vectors-negative300.bin.gz...\n",
            "| [1 files][  1.5 GiB/  1.5 GiB]   31.8 MiB/s                                   \n",
            "Operation completed over 1 objects/1.5 GiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppwVxWSJQoDg"
      },
      "source": [
        "import gensim\n",
        "import spacy\n",
        "\n",
        "# Path to google news vectors\n",
        "google_news_path = \"./vqa-dataset-bucket/GoogleNews-vectors-negative300.bin.gz\"\n",
        "\n",
        "# Load google news vecs in gensim\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(google_news_path, binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ppyE3SqXCy4",
        "outputId": "892c924d-2f66-40d8-dc67-9d4d1b3594c8"
      },
      "source": [
        "nlp = spacy.blank('en')\n",
        "\n",
        "# Loop through range of all indexes, get words associated with each index.\n",
        "# The words in the keys list will correspond to the order of the google embed matrix\n",
        "keys = model.vocab.keys()\n",
        "\n",
        "# Set the vectors for our nlp object to the google news vectors\n",
        "nlp.vocab.vectors = spacy.vocab.Vectors(data=model.syn0, keys=model.index2word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjy32bvLM60j"
      },
      "source": [
        "questions_matrix = get_questions_sum(training_questions, nlp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImqaSjRJ0UJY",
        "outputId": "81457328-06a3-464a-e9e0-8b334be9012c"
      },
      "source": [
        "questions_matrix[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7SzvNzkOSbf"
      },
      "source": [
        "pk.dump(questions_matrix, open('./questions_mat_50k','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBD5ZoN_ZlRR",
        "outputId": "bc85e1ab-2f32-4771-98b9-9d837a4275e7"
      },
      "source": [
        "# !gsutil cp  ./questions_mat_50k gs://{bucket_name}/questions_mat_50k\n",
        "# !gsutil cp  gs://{bucket_name}/questions_mat ./questions_mat\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BucketNotFoundException: 404 gs://{bucket_name} bucket does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I1NOzj7Z5Cp"
      },
      "source": [
        "# del nlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0aE0Yr0bZ0K"
      },
      "source": [
        "del questions\n",
        "del annotation\n",
        "del annotations\n",
        "del progress"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mM0x9NnU2CZ"
      },
      "source": [
        "questions_matrix = pk.load(open('./questions_mat_50k','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvRBEZgVDF4k"
      },
      "source": [
        "def get_answers_sum(answers, encoder):\n",
        "    y = encoder.transform(answers)\n",
        "\n",
        "    nb_classes = encoder.classes_.shape[0]\n",
        "    Y = np_utils.to_categorical(y, nb_classes)\n",
        "    del y\n",
        "    del nb_classes\n",
        "    return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XPOnoMkUYuf"
      },
      "source": [
        "encoded_answers = get_answers_sum(answers_train, lbl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8ptYTTpW03B"
      },
      "source": [
        "# pk.dump(encoded_answers, open('./encoded_ans_50k','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "022bQfMPf7xw",
        "outputId": "9d8e7555-b9ac-4b6a-d694-24379a58cf53"
      },
      "source": [
        "# !gsutil cp  ./encoded_ans_50k gs://{bucket_name}/encoded_ans_50k\n",
        "#!gsutil cp  gs://{bucket_name}/encoded_ans ./encoded_ans\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BucketNotFoundException: 404 gs://{bucket_name} bucket does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWgBAjWJf-xs"
      },
      "source": [
        "# encoded_answers = pk.load(open('./encoded_ans','rb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwMZ8vrwb4Td"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.io.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [224, 224])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ_pmAr3GkkM"
      },
      "source": [
        "def get_image_data(img):\n",
        "  img = tf.io.read_file(img)\n",
        "  resized_image_data = decode_img(img)\n",
        "  return resized_image_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asPF6j6LDKyI"
      },
      "source": [
        "def get_tensors(text_input, image_input, y):\n",
        "  return (image_input, text_input), y\n",
        "\n",
        "\n",
        "def create_dataset(question_matrix,image_input, encoded_answers):\n",
        "  question_dataset = tf.convert_to_tensor(question_matrix)\n",
        "  question_dataset = tf.data.Dataset.from_tensor_slices(question_dataset)\n",
        "\n",
        "  images = tf.data.Dataset.list_files(image_input)\n",
        "  image_tensor = images.map(get_image_data)\n",
        "  y_dataset = tf.convert_to_tensor(encoded_answers)\n",
        "  y_dataset = tf.data.Dataset.from_tensor_slices(y_dataset)\n",
        "  dataset = tf.data.Dataset.zip((question_dataset, image_tensor, y_dataset))\n",
        "  dataset = dataset.shuffle(1000)\n",
        "  dataset = dataset.batch(100)\n",
        "  dataset = dataset.map(get_tensors)\n",
        "  dataset = dataset.prefetch(3)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuO6-NjkGiep"
      },
      "source": [
        "image_train = [os.path.join('/content/vqa-dataset-bucket/val2014','COCO_val2014_'+str(image).zfill(12)+'.jpg') for image in images_train]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR_8_GnxLFJt"
      },
      "source": [
        "train_dataset = create_dataset(questions_matrix, image_train, encoded_answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64b-RcuTNaAG"
      },
      "source": [
        "# Import Keras \n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "# Define CNN for Image Input\n",
        "vision_model = Sequential()\n",
        "vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
        "vision_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "vision_model.add(MaxPooling2D((2, 2)))\n",
        "vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "vision_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "vision_model.add(MaxPooling2D((2, 2)))\n",
        "vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "vision_model.add(MaxPooling2D((2, 2)))\n",
        "vision_model.add(Flatten())\n",
        "\n",
        "image_input = Input(shape=(224, 224, 3))\n",
        "encoded_image = vision_model(image_input)\n",
        "\n",
        "# Define RNN for language input\n",
        "question_input=  tf.keras.layers.Input(shape=(None,))\n",
        "embedded_question= tf.keras.layers.Embedding(300, output_dim=50)(question_input)\n",
        "encoded_question= tf.keras.layers.LSTM(100)(embedded_question)\n",
        "\n",
        "# Combine CNN and RNN to create the final model\n",
        "merged = keras.layers.concatenate([encoded_question, encoded_image])\n",
        "dense_layer = Dense(2000, activation='relu')(merged)\n",
        "output = Dense(1000, activation='softmax')(dense_layer)\n",
        "vqa_model = Model(inputs=[image_input, question_input], outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odb6ga93LUiX",
        "outputId": "956857b9-cf53-4a29-fe5f-cda9622c7a69"
      },
      "source": [
        "vqa_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 50)     15000       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 100)          60400       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 160000)       1735488     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 160100)       0           lstm[0][0]                       \n",
            "                                                                 sequential[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2000)         320202000   concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1000)         2001000     dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 324,013,888\n",
            "Trainable params: 324,013,888\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkM5b3o7LHbK"
      },
      "source": [
        "vqa_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H8QSKscWj1U",
        "outputId": "9c7b8acb-8647-49e2-99b2-29f4ee43a0a0"
      },
      "source": [
        "history = vqa_model.fit(train_dataset, epochs=10, steps_per_epoch=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "50/50 [==============================] - 42s 527ms/step - loss: 26.9474 - accuracy: 0.1944\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 26s 527ms/step - loss: 4.4367 - accuracy: 0.1994\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 26s 527ms/step - loss: 4.2860 - accuracy: 0.2192\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 26s 527ms/step - loss: 4.2614 - accuracy: 0.2202\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 26s 528ms/step - loss: 4.2306 - accuracy: 0.2126\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 26s 528ms/step - loss: 4.2782 - accuracy: 0.2158\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 26s 527ms/step - loss: 4.2354 - accuracy: 0.2110\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 26s 527ms/step - loss: 4.2990 - accuracy: 0.2190\n",
            "Epoch 9/10\n",
            "43/50 [========================>.....] - ETA: 4s - loss: 4.2686 - accuracy: 0.2132WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need to use the repeat() function when building your dataset.\n",
            "50/50 [==============================] - 26s 521ms/step - loss: 4.2686 - accuracy: 0.2132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSyIa2MJXQ6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82eeab44-c029-4fd4-d3bc-992e23bbc73f"
      },
      "source": [
        "# vqa_model.save(\"vqa_model_word2vec_lstm_50k\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: vqa_model_word2vec_lstm_50k/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: vqa_model_word2vec_lstm_50k/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQwwzdEKNmsh",
        "outputId": "a7dedb31-75e0-4c34-bf3e-f32cab4f9e51"
      },
      "source": [
        "# !gsutil -m cp -r ./vqa_model_word2vec_lstm gs://{bucket_name}/vqa_model_word2vec_lstm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://./vqa_model_word2vec_lstm/saved_model.pb [Content-Type=application/octet-stream]...\n",
            "/ [0/4 files][    0.0 B/  1.8 GiB]   0% Done                                    \rCopying file://./vqa_model_word2vec_lstm/keras_metadata.pb [Content-Type=application/octet-stream]...\n",
            "/ [0/4 files][    0.0 B/  1.8 GiB]   0% Done                                    \rCopying file://./vqa_model_word2vec_lstm/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
            "Copying file://./vqa_model_word2vec_lstm/variables/variables.index [Content-Type=application/octet-stream]...\n",
            "/ [0/4 files][    0.0 B/  1.8 GiB]   0% Done                                    \r/ [0/4 files][    0.0 B/  1.8 GiB]   0% Done                                    \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "|\n",
            "Operation completed over 4 objects/1.8 GiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLVJxnYXYylV"
      },
      "source": [
        "filename = 'hello'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}